instrucciones corrida (estrategia):

(común a todos los modelos)
0_reparar_dataset.r: se corrigen los errores utilizando el método machine learning
1_drifting_y_fe.r: se corrige el drifting usando rank cero fijo

(modelo A)

2a_FE_historia: canaritos (0.3), lag1, lag2, tendencias (6 meses), max, min, ratioavg, promedio

3a_training_strategy_under:

    se aplica:

    PARAM$future       <- c( 202109 )
    PARAM$final_train  <- c( 201909, 201910, 201911, 201912, 202001, 202002, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107 )
    PARAM$train$training     <- c( 201907, 201908, 201909, 201910, 201911, 201912, 202001, 202002, 202011, 202012, 202101, 202102, 202103, 202104, 202105 )
    PARAM$train$validation   <- c( 202106 )
    PARAM$train$testing      <- c( 202107 ) 

    undersampling mayoritaria: 0.5

4a_HT_lightgbm_under.r: 18 horas de iteración bayesiana

5a_SM_semillero_lgbm_under: se corren 40 semillas para los modelos:

(modelo B)

2b_FE_historia:
    
    se aplica: 

        - lag1, lag2, promedio, tendencia (ventana 3 meses)

3b_training_strategy_under:

    se aplica:

    PARAM$future       <- c( 202109 )
    PARAM$final_train  <- c( 201909, 201910, 201911, 201912, 202001, 202002, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106, 202107 )
    PARAM$train$training     <- c( 201907, 201908, 201909, 201910, 201911, 201912, 202001, 202002, 202011, 202012, 202101, 202102, 202103, 202104, 202105 )
    PARAM$train$validation   <- c( 202106 )
    PARAM$train$testing      <- c( 202107 ) 

    sin undersampling

4a_HT_lightgbm_under.r: 50 iteraciones

5b_SM_semillero_lgbm_under: se corren 40 semillas para los modelos


Ensamble:

Se toman los vectores de probabilidades de cada semilla de cada modelo, se rankea cada una de las observaciones según la probabilidad, y se promedia ese ranking resultante.


Punto de corte: